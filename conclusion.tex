%!TEX root = main.tex


This paper revisited the solution-counting strategies for the well-known global cardinality constraint. It first highlights that in the computation of the initial result provided by~\cite{PesantQZ12}, a solution can be counted several times and, thus, the alleged upper bound is not an upper bound. We then provide a correct calculation of  an upper bound of the number of solutions for a global cardinality constraint. Finally, we build a benchmark for the $gcc$ constraint with a original method, which had not been done in the previous work, and we compare heuristics based on both quantities (the previous calculation by \cite{PesantQZ12} and our upper bound) on this benchmark. We  show that the two estimators lead to different choices within counting-based strategies. Finally, we solve a number of instances with both heuristics and compare the results. In practice, neither heuristic dominates the other: the counting-based heuristics used with the estimator from \cite{PesantQZ12} performs slightly better on instances with a high density of edges, \textit{i.e.} instances where the domains are rather large and of comparable sizes. Our bound performs slightly better on instances with a lower density of edges, \textit{i.e.} instances with more heterogeneous domains.

Though the former result is not an upper bound, it can now be seen as an estimator that can be used to guide the search, as an alternative way. That is probably why the error was difficult to spot. Our assumption is the following: when an estimator/bound used inside a counting-based heuristic, the correlation between the estimator and the actual number of solutions is much more important that the estimator accuracy. Now that we do have an upper-bound of the number of solutions, new questions can be investigated: how do different estimators compare to this upper bound? Is it possible to use our methodology (both on the calculation techniques and the benchmark generation) to introduce average-case estimators, or estimators based on probabilistic approaches? All these questions will be investigated as future works.

As further research, it would be interesting to extend our counting methods to other constraints of the same family, \textit{i.e.} cardinality constraints such as \texttt{alldifferent}, \texttt{atmost} and \texttt{atleast}, which can all be seen as specifications of the $\texttt{global\_cardinality}$ constraint and feature the same data structure, a bipartite graph. An extension of these counting constraint is the \texttt{nvalue} constraint, whose generalized arc-consistency is NP-hard: having either a bound or an estimator for this constraint would be very valuable inside a solver. The natural question which then arises is the following: assume that all cardinality constraints come with either upper-bounds of their number of solutions, or estimators. Given a problem featuring several such constraints, how to combine these bounds to efficiently guide the search? 

Finally, bound or estimations of solutions can be useful in other context than search heuristics. In particular, one of the current challenges in CP is to produce solutions which widely cover the set of solutions. On practical applications, solvers may be used by people who are not CP experts, and even not computer scientists (there are many examples in medicine \cite{BettsMRTLEH15,DickersonMPST16}, computer graphics \cite{TaoCL08}, disaster management \cite{Hentenryck13}, computer music \cite{Hooker16,TA2011}...). In this context, users may have to rate the solutions produced by the solver or choose one. Yet, due to the systematic search process, a solver often provides solutions in a given order. In practice, two solutions in a row are often very similar in terms of values of the variables. This is unsatisfactory to the user and may drive him/her away of the technology. A better approach would be to provide solutions uniformly sampled in the solution space. Doing this implies to choose randomly the instanciation at each node of the search space, so that the random draw is uniform within \textit{the set of solutions of the subtree of this node} (and not of the domains of the variables). Counting solutions, or estimating/bounding their number, has thus promising applications to the design of better solvers for non-expert users.
 
 %The main issue of those estimators on $\texttt{global\_cardinality}$ constraints, is that they require a lot of complex operations. Every instantiation for each constraint is tested and propagated. Computing them each time a decision has to be made is very time consuming. Indeed, we need to compute the Lower Bound Graph, the Upper Bound Graph then we need to estimate the number of matchings on these graphs. This is why, in the presented experiments, the instantiations ordering is only made in the beginning of the search. Thus, at each branch of the search tree, we do not necessarily visit first the space where there are more solutions at this point of the search. That is why estimators that are faster to compute are needed for this constraint. 
 
 